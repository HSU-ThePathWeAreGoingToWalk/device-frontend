import React, { useState, useEffect, useRef } from "react";
import { ReactMic } from 'react-mic';
import "./BusStop.css";
import characterImg from "./char.png";
import characterSadImg from "./char_sad.png";
// import bubbleImg from "./bubble.png"; // bubbleImgëŠ” ì½”ë“œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šì•„ ì£¼ì„ ì²˜ë¦¬
import axios from "axios";
// import busImg from "./bus.png"; // ì•„ì´ì½˜ ëŒ€ì‹  í…ìŠ¤íŠ¸ ì‚¬ìš©ìœ¼ë¡œ ì£¼ì„ ì²˜ë¦¬
// import subwayImg from "./subway.png";
// import shipImg from "./ship.png";
// import walkingImg from "./walking.png";
import Map from '../components/Map/Map.tsx';
// import { v4 as uuidv4 } from "uuid"; // uuidv4ëŠ” ì½”ë“œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šì•„ ì£¼ì„ ì²˜ë¦¬
import ciscoLogo from "./cisco_logo.png";
import OpenAI from 'openai';

// API ê¸°ë³¸ URL ì„¤ì •
const API_BASE_URL = "http://localhost:9000"; // ì‹¤ì œ API ì„œë²„ URLë¡œ ë³€ê²½ í•„ìš”

// --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
// !!! ë³´ì•ˆ ê²½ê³  !!!
// ë¸Œë¼ìš°ì €ì—ì„œ API í‚¤ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë§¤ìš° ìœ„í—˜í•©ë‹ˆë‹¤.
// ì‹¤ì œ ë°°í¬ í™˜ê²½ì—ì„œëŠ” ì„œë²„ ì¸¡ì—ì„œ OpenAI APIë¥¼ í˜¸ì¶œí•˜ë„ë¡ ë°±ì—”ë“œ í”„ë¡ì‹œë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
// ê°œë°œ ëª©ì ìœ¼ë¡œë§Œ dangerouslyAllowBrowser ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.
const openai = new OpenAI({
  apiKey: process.env.REACT_APP_OPENAI_API_KEY, // .env íŒŒì¼ì— REACT_APP_OPENAI_API_KEY=your_key í˜•ì‹ìœ¼ë¡œ ì €ì¥
  dangerouslyAllowBrowser: true, // í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€!
});
// --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë ---


function BusStop() {
  const audioRef = useRef(null);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [currentTime, setCurrentTime] = useState("");
  const [isDay, setIsDay] = useState(true);
  const [weatherData, setWeatherData] = useState({ dust: "ì¢‹ìŒ", temperature: "17" });
  const [isEmergency, setIsEmergency] = useState(false);
  const [busInfo, setBusInfo] = useState({
    buses: [],
    success: false
  });
  const [isRecording, setIsRecording] = useState(false);
  // const [audioBlob, setAudioBlob] = useState(null); // ë…¹ìŒëœ Blobì€ ì „ì†¡ í›„ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ìƒíƒœ ì œê±° ê°€ëŠ¥
  const [userMessage, setUserMessage] = useState(""); // STT ê²°ê³¼ í‘œì‹œìš© (ì„ íƒ ì‚¬í•­)
  const [isLoading, setIsLoading] = useState(false); // API í˜¸ì¶œ ë¡œë”© ìƒíƒœ
  const [isTranscribing, setIsTranscribing] = useState(false); // ìŒì„± ì¸ì‹ ì¤‘ ìƒíƒœ ì¶”ê°€
  const [userQuestion, setUserQuestion] = useState(""); // ì±—ë´‡ì— ë³´ë‚¸ ì§ˆë¬¸
  const [responseType, setResponseType] = useState(null);
  const [responseData, setResponseData] = useState(null);
  const [isMuted, setIsMuted] = useState(() => {
    const savedMuteState = localStorage.getItem('isMuted');
    return savedMuteState ? JSON.parse(savedMuteState) : false;
  });
  const [realtimeText, setRealtimeText] = useState(""); // ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‹¤ì‹œê°„ ìƒíƒœ ë©”ì‹œì§€
  const [showMap, setShowMap] = useState(false); // ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìƒíƒœì¸ ê²ƒ ê°™ì•„ í™•ì¸ í•„ìš”
  const [mapData, setMapData] = useState(null); // ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìƒíƒœì¸ ê²ƒ ê°™ì•„ í™•ì¸ í•„ìš”
  const [isRefreshing, setIsRefreshing] = useState(false);
  const [inputText, setInputText] = useState(""); // í…ìŠ¤íŠ¸ ì…ë ¥ìš© ìƒíƒœ

  const CURRENT_LOCATION = {
    lng: 127.29453611111111,
    lat: 34.620875
  };

  const isRecordingRef = useRef(isRecording);
  // isRecording ìƒíƒœ ë³€ê²½ ì‹œ refë„ ì—…ë°ì´íŠ¸
  useEffect(() => {
    isRecordingRef.current = isRecording;
  }, [isRecording]);

  const updateTime = () => {
    const now = new Date();
    const hours = now.getHours();
    const minutes = now.getMinutes();
    setCurrentTime(`${hours < 10 ? "0" + hours : hours}:${minutes < 10 ? "0" + minutes : minutes}`);
    setIsDay(hours >= 6 && hours < 18);
  };

  useEffect(() => {
    updateTime();
    const interval = setInterval(updateTime, 60000);
    return () => clearInterval(interval);
  }, []);

  // ë²„ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  useEffect(() => {
    const fetchBusData = async () => {
      try {
        const response = await axios.get(`${API_BASE_URL}/bus`);
        console.log("ë²„ìŠ¤ ë°ì´í„°:", response.data);

        const sortedBuses = response.data
          .sort((a, b) => a.arrival_minutes - b.arrival_minutes)
          .slice(0, 3);

        setBusInfo({
          buses: sortedBuses,
          success: true
        });
      } catch (error) {
        console.error("ğŸš Bus data fetch error:", error);
        setBusInfo({
          buses: [],
          success: false
        });
      }
    };
    fetchBusData();
    const busInterval = setInterval(fetchBusData, 30000);
    return () => clearInterval(busInterval);
  }, []);

  // SSE ì¸ì‚¬ ë©”ì‹œì§€ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  useEffect(() => {
    const eventSource = new EventSource('http://localhost:3001/greeting-events');
    eventSource.addEventListener('greeting', (e) => {
      const data = JSON.parse(e.data);
      if (data.action === 'start') {
        startGreetingSequence();
      }
    });
    return () => {
      eventSource.close();
    };
  }, []); // ë¹ˆ ë°°ì—´ë¡œ ìˆ˜ì •í•˜ì—¬ ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ í•¨

  // OpenAI TTS í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const speakText = async (text) => {
    if (isMuted) return;

    try {
      // TTS ì‹œì‘ ì „ ë…¹ìŒ ì¤‘ì§€
      if (isRecordingRef.current) {
        stopRecording(); // ë‚´ë¶€ì ìœ¼ë¡œ isRecordingRef.current = false ì„¤ì •
      }
      setIsSpeaking(true);

      const response = await openai.audio.speech.create({
        model: 'gpt-4o-mini-tts', // ìµœì‹  ëª¨ë¸ í™•ì¸ í•„ìš”
        voice: 'sage',
        input: text,
        // instructions ì œê±° (v1 APIì—ì„œëŠ” ì´ ì˜µì…˜ ì—†ìŒ)
      });

      const audioBlob = await response.blob();
      const audioUrl = URL.createObjectURL(audioBlob);

      // ê¸°ì¡´ ì˜¤ë””ì˜¤ ì¤‘ì§€ ë° í•´ì œ
      if (audioRef.current) {
        audioRef.current.pause();
        URL.revokeObjectURL(audioRef.current.src);
      }

      const audio = new Audio(audioUrl);
      audioRef.current = audio;
      await audio.play();

      audio.onended = () => {
        URL.revokeObjectURL(audioUrl);
        audioRef.current = null;
        setIsSpeaking(false);
        // TTS ì¢…ë£Œ í›„ ìŒì†Œê±° ìƒíƒœê°€ ì•„ë‹ˆë©´ ìë™ìœ¼ë¡œ ë…¹ìŒ ì‹œì‘
        if (!isMuted) {
           setTimeout(() => {
             // isSpeaking ìƒíƒœê°€ falseë¡œ í™•ì‹¤íˆ ì—…ë°ì´íŠ¸ ëœ í›„ ë…¹ìŒ ì‹œì‘
             // isRecordingRef.currentê°€ ì—¬ì „íˆ falseì¸ì§€ ë‹¤ì‹œ í™•ì¸
             if (!isRecordingRef.current) {
                 startRecording();
             }
           }, 300); // ì•½ê°„ì˜ ë”œë ˆì´ ì¶”ê°€
        }
      };
    } catch (error) {
      console.error('OpenAI TTS ì—ëŸ¬:', error);
      setIsSpeaking(false); // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ isSpeaking ìƒíƒœ ì´ˆê¸°í™”
    }
  };

  // ìŒì†Œê±° í† ê¸€ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const toggleMute = () => {
    const newMuteState = !isMuted;
    setIsMuted(newMuteState);
    localStorage.setItem('isMuted', JSON.stringify(newMuteState));

    if (audioRef.current) {
      audioRef.current.pause();
      URL.revokeObjectURL(audioRef.current.src);
      audioRef.current = null;
      setIsSpeaking(false); // ìŒì†Œê±° ì‹œ isSpeaking ìƒíƒœ ê°•ì œ í•´ì œ
    }
     // ìŒì†Œê±° í•´ì œ ì‹œ ë…¹ìŒ ì‹œì‘/ì¤‘ì§€ ë¡œì§ ì¶”ê°€
     if (!newMuteState && !isSpeaking && !isRecordingRef.current) {
        startRecording(); // ìŒì†Œê±° í•´ì œë˜ê³ , ë§í•˜ëŠ” ì¤‘ ì•„ë‹ˆê³ , ë…¹ìŒ ì¤‘ ì•„ë‹ˆë©´ ë…¹ìŒ ì‹œì‘
     } else if (newMuteState && isRecordingRef.current) {
        stopRecording(); // ìŒì†Œê±°í•˜ë©´ ë…¹ìŒ ì¤‘ì§€
     }
  };

  // ë…¹ìŒ ì‹œì‘
  const startRecording = () => {
    // ë§í•˜ëŠ” ì¤‘ì´ê±°ë‚˜ ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ë©´ ì‹œì‘í•˜ì§€ ì•ŠìŒ
    if (isSpeaking || isRecordingRef.current) return;

    console.log("ë…¹ìŒ ì‹œì‘ ìš”ì²­");
    setIsRecording(true);
    // isRecordingRef.current = true; // useEffectë¡œ ì²˜ë¦¬ë¨
    setRealtimeText("ë“£ëŠ” ì¤‘ì…ë‹ˆë‹¤...");
    setUserMessage(""); // ì´ì „ ë©”ì‹œì§€ ì´ˆê¸°í™”
  };

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    // ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆë©´ ì¤‘ì§€í•˜ì§€ ì•ŠìŒ
    if (!isRecordingRef.current) return;

    console.log("ë…¹ìŒ ì¤‘ì§€ ìš”ì²­");
    setIsRecording(false);
    // isRecordingRef.current = false; // useEffectë¡œ ì²˜ë¦¬ë¨
    setRealtimeText(""); // ìƒíƒœ ë©”ì‹œì§€ ì´ˆê¸°í™”
  };

  // ReactMic ë…¹ìŒ ì™„ë£Œ ì½œë°± -> OpenAI STT í˜¸ì¶œ
  const onStopRecording = (recordedBlob) => {
    console.log('ë…¹ìŒ ì™„ë£Œ, Blob:', recordedBlob);
    if (!recordedBlob || recordedBlob.blobSize < 1024) { // ë„ˆë¬´ ì‘ì€ íŒŒì¼ì€ ë¬´ì‹œ (ì„ íƒ ì‚¬í•­)
      console.log("ë…¹ìŒëœ ë°ì´í„°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤.");
      setRealtimeText("ì¸ì‹í•  ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.");
       // ë…¹ìŒ ì¬ì‹œì‘ ë¡œì§ (ì„ íƒì )
       if (!isMuted && !isSpeaking) {
         setTimeout(() => {
           if (!isRecordingRef.current) startRecording();
         }, 1000); // 1ì´ˆ í›„ ë‹¤ì‹œ ë…¹ìŒ ì‹œë„
       }
      return;
    }
    // setAudioBlob(recordedBlob.blob); // Blob ì €ì¥ ë¶ˆí•„ìš”
    transcribeWithOpenAI(recordedBlob.blob); // STT í•¨ìˆ˜ í˜¸ì¶œ
  };

  // --- OpenAI Whisper STT í˜¸ì¶œ í•¨ìˆ˜ ---
  const transcribeWithOpenAI = async (audioBlob) => {
    if (!audioBlob) return;

    setIsTranscribing(true); // ìŒì„± ì¸ì‹ ì‹œì‘ ìƒíƒœ
    setRealtimeText("ìŒì„± ì¸ì‹ ì¤‘..."); // ì‚¬ìš©ìì—ê²Œ ìƒíƒœ ì•Œë¦¼
    setUserMessage(""); // ì´ì „ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì´ˆê¸°í™”

    try {
      // Blobì„ File ê°ì²´ë¡œ ë³€í™˜ (Whisper APIëŠ” File ê°ì²´ë¥¼ ë°›ìŒ)
      const audioFile = new File([audioBlob], "audio.wav", { type: audioBlob.type });

      console.log("OpenAI STT API í˜¸ì¶œ ì‹œì‘");
      const response = await openai.audio.transcriptions.create({
        model: "whisper-1", // ì‚¬ìš©í•  Whisper ëª¨ë¸
        file: audioFile,
        // language: "ko", // í•„ìš”ì‹œ ì–¸ì–´ ì½”ë“œ ëª…ì‹œ (ì„ íƒ ì‚¬í•­)
        // response_format: "text" // í…ìŠ¤íŠ¸ë§Œ í•„ìš”í•œ ê²½ìš°
      });
      console.log("OpenAI STT ì‘ë‹µ:", response);

      const transcribedText = response.text; // Whisper v1ì€ response.text ë¡œ ë°˜í™˜
      setUserMessage(transcribedText); // ì¸ì‹ëœ í…ìŠ¤íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ (í™”ë©´ì— í‘œì‹œ)
      setRealtimeText(transcribedText); // ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì˜ì—­ì—ë„ í‘œì‹œ

      if (transcribedText && transcribedText.trim().length > 0) {
        sendMessageToAPI(transcribedText); // ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ì±—ë´‡ APIë¡œ ì „ì†¡
      } else {
        setRealtimeText("ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.");
         // ë…¹ìŒ ì¬ì‹œì‘ ë¡œì§ (ì„ íƒì )
         if (!isMuted && !isSpeaking) {
           setTimeout(() => {
             if (!isRecordingRef.current) startRecording();
           }, 1000);
         }
      }

    } catch (error) {
      console.error("OpenAI STT Error:", error);
      setRealtimeText("ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      // ì—ëŸ¬ ë°œìƒ ì‹œ ë…¹ìŒ ì¬ì‹œì‘ ë¡œì§ (ì„ íƒì )
       if (!isMuted && !isSpeaking) {
         setTimeout(() => {
           if (!isRecordingRef.current) startRecording();
         }, 1000);
       }
    } finally {
      setIsTranscribing(false); // ìŒì„± ì¸ì‹ ì¢…ë£Œ ìƒíƒœ
    }
  };

  // ì‚¬ìš© ì•ˆ í•¨: ì™¸ë¶€ STT ì„œë²„ í˜¸ì¶œ í•¨ìˆ˜ ì œê±°
  // const sendAudioToSTT = async (audioBlob) => { ... }

  // ì±—ë´‡ API í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€, ì•½ê°„ì˜ ì •ë¦¬)
  const sendMessageToAPI = async (message) => {
    if (!message || message.trim() === "") {
      console.log("ë¹ˆ ë©”ì‹œì§€ëŠ” ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      // ë¹ˆ ë©”ì‹œì§€ í›„ ë…¹ìŒ ì¬ì‹œì‘
       if (!isMuted && !isSpeaking) {
         setTimeout(() => {
           if (!isRecordingRef.current) startRecording();
         }, 500);
       }
      return;
    }

    setIsLoading(true); // ì±—ë´‡ ì‘ë‹µ ë¡œë”© ì‹œì‘
    setUserQuestion(message); // ë³´ë‚¸ ì§ˆë¬¸ ì €ì¥
    setRealtimeText(""); // STT ê²°ê³¼ í…ìŠ¤íŠ¸ëŠ” ì§€ì›€ (ì±—ë´‡ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°)
    setResponseType(null); // ì´ì „ ì‘ë‹µ íƒ€ì… ì´ˆê¸°í™”
    setResponseData(null); // ì´ì „ ì‘ë‹µ ë°ì´í„° ì´ˆê¸°í™”


    console.log(`ì±—ë´‡ API í˜¸ì¶œ: ${message}`);
    try {
      const response = await axios.post(`${API_BASE_URL}/chat`, {
        message: message
      });

      const data = response.data;
      console.log("ì±—ë´‡ ì„œë²„ ì‘ë‹µ:", data);

      let responseText = ''; // TTSë¡œ ì½ì–´ì¤„ í…ìŠ¤íŠ¸

      // ì‘ë‹µ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ê³¼ ìœ ì‚¬)
      if (data.places && data.coordinates) {
        setResponseType('location');
        setResponseData(data); // ì „ì²´ ë°ì´í„° ì €ì¥
        responseText = data.conversation_response;
      }
      else if (data.routes_text && data.coordinates) {
        setResponseType('route');
        setResponseData(data);
        responseText = data.conversation_response;
      }
      else if (data.available_buses && data.arrival_times) {
        setResponseType('bus');
        setResponseData(data);
        responseText = data.conversation_response;
      }
      else { // ì¼ë°˜ ì‘ë‹µ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
        setResponseType('notice');
        // ë°±ì—”ë“œ ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ response í•„ë“œê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ conversation_response ìš°ì„  ì‚¬ìš©
        const noticeText = data.conversation_response || data.response || "ì£„ì†¡í•©ë‹ˆë‹¤. ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”.";
        setResponseData({
          response: noticeText,
          success: !(data.error) // ì—ëŸ¬ í•„ë“œê°€ ìˆëŠ”ì§€ ì—¬ë¶€ë¡œ ì„±ê³µ íŒë³„ (ë°±ì—”ë“œì™€ í˜‘ì˜ í•„ìš”)
        });
        responseText = noticeText;
      }

      // ìŒì†Œê±° ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ TTS ì‹¤í–‰
      if (!isMuted && responseText) {
        await speakText(responseText); // speakText ë‚´ë¶€ì—ì„œ TTS í›„ ë…¹ìŒ ì¬ì‹œì‘ ë¡œì§ ìˆìŒ
      } else {
        // TTSê°€ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš° (ìŒì†Œê±° ë“±), ìˆ˜ë™ìœ¼ë¡œ ë…¹ìŒ ì¬ì‹œì‘ ë¡œì§ í•„ìš”
        if (!isMuted && !isSpeaking && !isRecordingRef.current) {
          setTimeout(() => startRecording(), 500); // ì±—ë´‡ ì‘ë‹µ í‘œì‹œ í›„ ì ì‹œ ë’¤ ë…¹ìŒ ì‹œì‘
        }
      }

      // setUserMessage(""); // ì±—ë´‡ ì‘ë‹µ í›„ ì‚¬ìš©ì ë©”ì‹œì§€ ì´ˆê¸°í™” (STT ê²°ê³¼ë¥¼ ì ì‹œ ë³´ì—¬ì£¼ë ¤ë©´ ì£¼ì„ ì²˜ë¦¬)
      // setRealtimeText(""); // ë¡œë”© ëë‚˜ë©´ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”

    } catch (error) {
      console.error("ì±—ë´‡ API Error:", error);
      setResponseType('notice');
      const errorMsg = "ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë²„ì™€ í†µì‹  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
      setResponseData({
        response: errorMsg,
        success: false
      });
       // ì˜¤ë¥˜ ë°œìƒ ì‹œ TTS ì‹¤í–‰ (ì„ íƒì )
       if (!isMuted) {
         await speakText(errorMsg);
       } else {
         // TTS ì‹¤í–‰ ì•ˆë  ì‹œ ë…¹ìŒ ì¬ì‹œì‘ ë¡œì§
         if (!isMuted && !isSpeaking && !isRecordingRef.current) {
           setTimeout(() => startRecording(), 500);
         }
       }
    } finally {
      setIsLoading(false); // ì±—ë´‡ ì‘ë‹µ ë¡œë”© ì¢…ë£Œ
    }
  };

  // --- ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼) ---
  const LocationComponent = ({ data }) => (
    <div className="response-card location">
      {data.coordinates && (
        <div className="map-container">
          <Map
            coordinates={[
              [CURRENT_LOCATION.lng, CURRENT_LOCATION.lat],
              ...data.coordinates
            ]}
            type="location"
            places={["í˜„ì¬ ìœ„ì¹˜", ...data.places]}
          />
        </div>
      )}
      <ul>
        {data.places.map((place, index) => (
          <li key={index}>âœ… {place}</li>
        ))}
      </ul>
    </div>
  );

  const RouteComponent = ({ data }) => (
    <div className="response-card route">
      {data.coordinates && (
        <div className="map-container">
          <Map
            coordinates={data.coordinates}
            type="route"
          />
        </div>
      )}
      <div className="route-details">
        <p><strong>ğŸš¶ ì´ë™ ê²½ë¡œ:</strong></p>
        {data.routes_text.split('\n').map((step, index) => (
          <div key={index} className="route-step">{step}</div>
        ))}
      </div>
    </div>
  );

  const BusComponent = ({ data }) => (
    <div className="response-card bus">
      {/* <p>{data.conversation_response}</p> conversation_responseëŠ” TTSë¡œ ì²˜ë¦¬ */}
      <table>
        <thead>
          <tr>
            <th>ë²„ìŠ¤ ë²ˆí˜¸</th>
            <th>ì˜ˆìƒ ë„ì°© ì‹œê°„</th>
          </tr>
        </thead>
        <tbody>
          {data.arrival_times.map((bus, index) => (
            <tr key={index}>
              <td>{data.available_buses[index]}</td>
              {/* ë„ì°© ì‹œê°„ì´ ìˆ«ì ë˜ëŠ” ê°ì²´ì¼ ìˆ˜ ìˆìŒì„ ì²˜ë¦¬ */}
              <td>{typeof bus === 'object' ? `${bus.expectedArrival}ë¶„` : `${bus}ë¶„`}</td>
            </tr>
          ))}
        </tbody>
      </table>
      {data.alternative_path && (
        <div className="alternative-route">
          <h4>ğŸš¶ ëŒ€ì²´ ê²½ë¡œ</h4>
          {/* ëŒ€ì²´ ê²½ë¡œ ë°ì´í„° êµ¬ì¡°ê°€ RouteComponentì™€ í˜¸í™˜ë˜ëŠ”ì§€ í™•ì¸ í•„ìš” */}
          <RouteComponent data={data.alternative_path} />
        </div>
      )}
    </div>
  );

  const NoticeComponent = ({ data }) => (
    <div className="response-card notice">
      <p className={data.response === "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ì€ ì–´ë”” ê°€ì‹œë‚˜ìš”?" ? "greeting-text" : ""}>
        {data.response}
      </p>
    </div>
  );

  // ì‘ë‹µ ë Œë”ë§ ë¡œì§ (ë¡œë”© ìƒíƒœ ì„¸ë¶„í™”)
  const renderResponse = () => {
    // ì´ˆê¸° ìƒíƒœ ë˜ëŠ” ì•„ë¬´ëŸ° ì‘ë‹µ/ë¡œë”©ì´ ì—†ì„ ë•Œ
    if (!isLoading && !isTranscribing && !responseData && !realtimeText) {
      return (
        <div className="response-container">
          <p className="initial-message">
            {/* ì´ˆê¸° ë©”ì‹œì§€ ë³€ê²½ */}
            ëŒ€í™” ì‹œì‘ ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜, ìŒì„± ì•ˆë‚´ í›„ ë§ì”€í•´ì£¼ì„¸ìš”.
          </p>
        </div>
      );
    }
    // ì±—ë´‡ ì‘ë‹µ ëŒ€ê¸° ì¤‘
    if (isLoading) {
      return (
        <div className="response-container">
           <div className="bot-response">
             <div className="loading-indicator">
               <div className="spinner"></div>
               {/* ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ */}
               <div className="loading-text">"{userQuestion}" ì— ëŒ€í•´ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...</div>
             </div>
           </div>
        </div>
      );
    }
    // ì±—ë´‡ ì‘ë‹µì´ ìˆì„ ë•Œ
    if (responseData) {
       return (
         <div className="response-container">
           <div className="bot-response">
             {responseType === 'location' && <LocationComponent data={responseData} />}
             {responseType === 'route' && <RouteComponent data={responseData} />}
             {responseType === 'bus' && <BusComponent data={responseData} />}
             {responseType === 'notice' && <NoticeComponent data={responseData} />}
           </div>
         </div>
       );
    }
     // ìŒì„± ì¸ì‹ ì¤‘ì´ê±°ë‚˜ STT ê²°ê³¼ í‘œì‹œ ì¤‘ì¼ ë•Œ (ì„ íƒì )
     // if (isTranscribing || realtimeText) {
     //   return null; // realtimeText ì»¨í…Œì´ë„ˆê°€ ë³„ë„ë¡œ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” null ë°˜í™˜
     // }

    // ìœ„ì˜ ëª¨ë“  ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš° (ì˜ˆ: ì˜¤ë¥˜ í›„ ìƒíƒœ)
    return null;
  };


  // í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const refreshPage = () => {
    setIsRefreshing(true);
    setTimeout(() => {
      setIsRefreshing(false);
      window.location.reload();
    }, 1000);
  };

  // ì¸ì‚¬ ì‹œí€€ìŠ¤ (ê¸°ì¡´ ë¡œì§ ìœ ì§€, speakText í›„ ë…¹ìŒ ì‹œì‘ ë¡œì§ì€ speakText ë‚´ë¶€ì— í†µí•©ë¨)
  const startGreetingSequence = async () => {
    const greetingText = "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ì€ ì–´ë”” ê°€ì‹œë‚˜ìš”?";
    setResponseType('notice');
    setResponseData({
      response: greetingText,
      success: true
    });

    try {
      // ìŒì†Œê±° ìƒíƒœ ì•„ë‹ ë•Œë§Œ ì¸ì‚¬ë§ ì¬ìƒ ë° ë…¹ìŒ ì‹œì‘ ìœ ë„
      if (!isMuted) {
          await speakText(greetingText);
          // speakTextì˜ onended ì½œë°±ì—ì„œ ë…¹ìŒ ì‹œì‘ì„ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¶”ê°€ í˜¸ì¶œ ë¶ˆí•„ìš”
          // await new Promise(resolve => setTimeout(resolve, 1000)); // ë¶ˆí•„ìš”í•œ ëŒ€ê¸° ì œê±°
          // setTimeout(() => { ... }, 500); // speakText ë‚´ë¶€ì—ì„œ ì²˜ë¦¬
      } else {
          // ìŒì†Œê±° ìƒíƒœì¼ ë•ŒëŠ” ì¸ì‚¬ë§ í‘œì‹œë§Œ í•˜ê³  ëŒ€ê¸°
          console.log("ìŒì†Œê±° ìƒíƒœë¼ ì¸ì‚¬ë§ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.");
      }
    } catch (error) {
      console.error("Greeting sequence error:", error);
      // ì—ëŸ¬ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ (ì„ íƒì )
      setResponseType('notice');
      setResponseData({
         response: "ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
         success: false
      });
    }
  };

  // ê¸´ê¸‰ í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const handleEmergency = async () => {
    try {
      // ì§„í–‰ ì¤‘ì¸ ì˜¤ë””ì˜¤/ë…¹ìŒ ì¤‘ë‹¨
      if (audioRef.current) {
        audioRef.current.pause();
        URL.revokeObjectURL(audioRef.current.src); // ë©”ëª¨ë¦¬ í•´ì œ
        audioRef.current = null;
        setIsSpeaking(false);
      }
      if (isRecordingRef.current) {
        stopRecording(); // ReactMic ì¤‘ì§€ ë° ìƒíƒœ ë³€ê²½
      }

      // ìƒíƒœ ì´ˆê¸°í™”
      setIsRecording(false);
      // isRecordingRef.current = false; // stopRecordingì—ì„œ ì²˜ë¦¬
      setRealtimeText("");
      setUserMessage("");
      setResponseType(null);
      setResponseData(null);
      setIsLoading(false);
      setIsTranscribing(false);


      const emergencyData = {
        timestamp: new Date().toISOString(),
        location: CURRENT_LOCATION,
        type: 'EMERGENCY_ALERT',
        deviceInfo: {
          userAgent: navigator.userAgent,
          platform: navigator.platform
        }
      };

      console.log("ê¸´ê¸‰ í˜¸ì¶œ ë°ì´í„° ì „ì†¡:", emergencyData);
      const response = await axios.post(
        `${API_BASE_URL}/emergency`,
        emergencyData,
        {
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );

      console.log("Emergency response:", response.data);
      // ë¹„ìƒ ëª¨ë“œ UI í‘œì‹œ (ìƒˆë¡œê³ ì¹¨ ëŒ€ì‹ )
      setIsEmergency(true);
       // setIsRefreshing(true); // ìƒˆë¡œê³ ì¹¨ ëŒ€ì‹  ëª¨ë‹¬ í‘œì‹œ
       // setTimeout(() => {
       //   setIsRefreshing(false);
       //   setIsEmergency(true);
       // }, 1000);
    } catch (error) {
      console.error("Emergency alert failed:", error);
      // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë¹„ìƒ ëª¨ë“œ UI í‘œì‹œ
      setIsEmergency(true);
    }
  };

  // ë¹„ìƒ ëª¨ë‹¬ ë‹«ê¸° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const handleCloseEmergency = () => {
    setIsEmergency(false);
    // ë¹„ìƒ ëª¨ë“œ ì¢…ë£Œ í›„ ë‹¤ì‹œ ì¸ì‚¬ ì‹œí€€ìŠ¤ë‚˜ ë…¹ìŒ ì‹œì‘ ê°€ëŠ¥ (ì„ íƒì )
    // startGreetingSequence(); // or startRecording();
  };

  // í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const handleInputChange = (e) => {
    setInputText(e.target.value);
  };

  // í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const handleSendMessage = () => {
    if (inputText.trim() === "") return;
    // í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œ í˜„ì¬ ë…¹ìŒ/ë§í•˜ê¸° ì¤‘ë‹¨
    if (isRecordingRef.current) stopRecording();
    if (isSpeaking && audioRef.current) {
        audioRef.current.pause();
        URL.revokeObjectURL(audioRef.current.src);
        audioRef.current = null;
        setIsSpeaking(false);
    }
    sendMessageToAPI(inputText); // ì±—ë´‡ API í˜¸ì¶œ
    setInputText(""); // ì…ë ¥ì°½ ë¹„ìš°ê¸°
  };

  // Enter í‚¤ë¡œ ì „ì†¡ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const handleKeyPress = (e) => {
    if (e.key === "Enter") {
      handleSendMessage();
    }
  };


  // --- JSX ë Œë”ë§ ---
  return (
    <div className="app-container">
      {/* Status Bar (ê¸°ì¡´ê³¼ ë™ì¼) */}
      <div className="status-bar">
        <img src={ciscoLogo} alt="Cisco Logo" className="cisco-logo" />
        <div className="time">
          {isDay ? (
            <svg /* Sun icon */ className="sun-icon" xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg>
          ) : (
            <svg /* Moon icon */ className="moon-icon" xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 A7 7 0 0 0 21 12.79z"></path></svg>
          )}
          {currentTime}
        </div>
        <button
          onClick={refreshPage}
          className={`voice-button refresh ${isRefreshing ? 'rotating' : ''}`}
          title="í™”ë©´ ìƒˆë¡œê³ ì¹¨"
        >
          <svg /* Refresh icon */ xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" fill="none" stroke="white" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8" /><path d="M21 3v5h-5" /><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16" /><path d="M3 21v-5h5" /></svg>
        </button>
        <div className="weather-info">
          <div className="dust">ëŒ€ê¸°ì§ˆ: {weatherData.dust}</div>
          <div className="temperature">ì˜¨ë„: {weatherData.temperature}Â°C</div>
        </div>
      </div>

      {/* Main content */}
      <div className="main-content">
        {/* Left column */}
        <div className="left-column">
          <div className="left-sub-column left">
            <div className="character-area">
              <img
                src={isMuted ? characterSadImg : characterImg}
                alt="ìºë¦­í„°"
                className="character-image"
              />
            </div>

            <div className="voice-control">
              {/* ReactMic ì»´í¬ë„ŒíŠ¸: ì‹œê°í™” ì—­í• ë§Œ í•˜ë„ë¡ ì„¤ì • ê°€ëŠ¥ */}
              <ReactMic
                record={isRecording}
                className="sound-wave" // CSS í´ë˜ìŠ¤ í™•ì¸
                onStop={onStopRecording} // ë…¹ìŒ ì¤‘ì§€ ì‹œ STT í˜¸ì¶œ íŠ¸ë¦¬ê±°
                strokeColor="#049FD9FF"
                backgroundColor="#ffffff"
                visualSetting="frequencyBars" // ë˜ëŠ” "sinewave"
                // strokeWidth={15} // frequencyBars ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”í•  ìˆ˜ ìˆìŒ
              />
              <div className="voice-buttons">
                {/* ë…¹ìŒ ì‹œì‘/ì¤‘ì§€ ë²„íŠ¼ */}
                <button
                  onClick={isRecording ? stopRecording : startRecording}
                  className={`voice-button toggle-record ${isRecording ? 'recording' : ''}`}
                  disabled={isSpeaking || isTranscribing} // ë§í•˜ëŠ” ì¤‘ ë˜ëŠ” ì¸ì‹ ì¤‘ì¼ ë•Œ ë¹„í™œì„±í™”
                  title={isRecording ? "ë…¹ìŒ ì¤‘ì§€" : "ëŒ€í™” ì‹œì‘"}
                >
                  {isRecording ? (
                     <svg /* Stop icon */ xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 24 24" fill="#FFFFFF" stroke="white" strokeWidth="1" strokeLinecap="round" strokeLinejoin="round"><rect x="6" y="6" width="12" height="12" rx="1" ry="1"/></svg>
                  ) : (
                     <svg /* Mic icon */ xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="white" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3z" /><path d="M19 10v2a7 7 0 0 1-14 0v-2" /><line x1="12" y1="19" x2="12" y2="22" /></svg>
                  )}
                </button>
                {/* ìŒì†Œê±° ë²„íŠ¼ */}
                <button
                  onClick={toggleMute}
                  className={`voice-button mute ${isMuted ? 'active' : ''}`}
                  title={isMuted ? 'ìŒì†Œê±° í•´ì œ' : 'ìŒì†Œê±°'}
                >
                  {isMuted ? (
                     <svg /* Mute icon */ xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="#049FD9FF" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5" /><line x1="23" y1="9" x2="17" y2="15" /><line x1="17" y1="9" x2="23" y2="15" /></svg>
                  ) : (
                     <svg /* Unmute icon */ xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="#049FD9FF" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5" /><path d="M15.54 8.46a5 5 0 0 1 0 7.07" /><path d="M19.07 4.93a10 10 0 0 1 0 14.14" /></svg>
                  )}
                </button>
              </div>
            </div>
          </div>

          {/* ì˜¤ë¥¸ìª½ ì„œë¸Œ ì»¬ëŸ¼: ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë° ì±—ë´‡ ì‘ë‹µ */}
          <div className="left-sub-column right">
            <div className="combined-response-area">
              {/* ì‹¤ì‹œê°„ ìƒíƒœ/STT ê²°ê³¼ í‘œì‹œ */}
              <div className="realtime-text-container">
                <div className="realtime-text">
                   {/* ìƒíƒœ ìš°ì„ ìˆœìœ„: ë…¹ìŒì¤‘ > ì¸ì‹ì¤‘ > STTê²°ê³¼/ì‚¬ìš©ìë©”ì‹œì§€ */}
                   {isRecording ? "ë“£ëŠ” ì¤‘ì…ë‹ˆë‹¤..." : isTranscribing ? "ìŒì„± ì¸ì‹ ì¤‘..." : realtimeText || userMessage }
                   {(isRecording || isTranscribing) && <span className="recording-indicator">â—</span>}
                </div>
              </div>
              {/* ì±—ë´‡ ì‘ë‹µ ë Œë”ë§ */}
              {renderResponse()}
            </div>
            {/* í…ìŠ¤íŠ¸ ì…ë ¥ ì˜ì—­ (ì„ íƒì ) */}
             {/* <div className="text-input-area">
                <input
                   type="text"
                   value={inputText}
                   onChange={handleInputChange}
                   onKeyPress={handleKeyPress}
                   placeholder="ë˜ëŠ” ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”..."
                   disabled={isLoading || isTranscribing || isSpeaking} // ë¡œë”©/ì¸ì‹/ë§í•˜ê¸° ì¤‘ ë¹„í™œì„±í™”
                />
                <button
                   onClick={handleSendMessage}
                   disabled={inputText.trim() === "" || isLoading || isTranscribing || isSpeaking} // ë¹„í™œì„±í™” ì¡°ê±´ ì¶”ê°€
                >
                   ì „ì†¡
                </button>
             </div> */}
          </div>
        </div>

        {/* Right column (ê¸°ì¡´ê³¼ ë™ì¼) */}
        <div className="right-column">
          <div className="info-area">
            <h2 className="bus-info-title">ë²„ìŠ¤ ë„ì°© ì •ë³´</h2>
            <div className="bus-info">
              {busInfo.success && busInfo.buses.length > 0 ? (
                <div className="bus-list">
                  {busInfo.buses.map((bus, index) => (
                    <div key={index} className="bus-item">
                      <div className="bus-number">{bus.bus_number}ë²ˆ</div>
                      <div className="arrival-time">{bus.arrival_minutes}ë¶„ í›„ ë„ì°©</div>
                      <div className="prev-count">{bus.prev_count}ì •ê±°ì¥ ì „</div>
                    </div>
                  ))}
                </div>
              ) : (
                <div className="no-bus-info">ë²„ìŠ¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤</div>
              )}
            </div>
          </div>
          <div className="emergency-button-container">
            <button onClick={handleEmergency} className="emergency-button">
              ê´€ë¦¬ì í˜¸ì¶œ
            </button>
          </div>
        </div>
      </div>

      {/* Map Overlay (ì‚¬ìš© ì—¬ë¶€ í™•ì¸ í•„ìš”, ê¸°ì¡´ê³¼ ë™ì¼) */}
      {showMap && mapData && (
        <div className="map-overlay">
          <Map
            coordinates={mapData.coordinates}
            type={mapData.type}
            places={mapData.places}
          />
          <button className="close-map-btn" onClick={() => setShowMap(false)}>
            ì§€ë„ ë‹«ê¸°
          </button>
        </div>
      )}

      {/* Emergency Overlay (ê¸°ì¡´ê³¼ ë™ì¼) */}
      {isEmergency && (
        <div className="emergency-overlay" onClick={handleCloseEmergency}>
          <div className="emergency-modal" onClick={(e) => e.stopPropagation()}>
            <h2>ë¹„ìƒ ë²„íŠ¼ì´ ëˆŒë ¸ìŠµë‹ˆë‹¤!</h2>
            <h2>ê´€ë¦¬ìì™€ ì—°ë½ ì‹œë„ì¤‘ì´ë‹ˆ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹­ì‹œì˜¤</h2>
          </div>
        </div>
      )}
    </div>
  );
}

export default BusStop;